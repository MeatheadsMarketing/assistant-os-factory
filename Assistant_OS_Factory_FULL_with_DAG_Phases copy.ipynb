{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c68aa273",
      "metadata": {
        "id": "c68aa273"
      },
      "source": [
        "# üß† Assistant OS Factory v1.0\n",
        "Includes full DAG Flow Builder (Phases 1‚Äì4) with GPT, Save/Load, and Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "af89771f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af89771f",
        "outputId": "2d60b03d-c968-4ea6-a0b3-2e6851e31ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "58c8d3a3",
      "metadata": {
        "id": "58c8d3a3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/assistant_markdown/\"\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"processed/\")\n",
        "LAUNCHER_DIR = os.path.join(BASE_DIR, \"streamlit_ready/\")\n",
        "DAG_FLOW_DIR = os.path.join(BASE_DIR, \"dag_flows/\")\n",
        "ZIP_EXPORT_PATH = os.path.join(BASE_DIR, \"assistant_bundle.zip\")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(LAUNCHER_DIR, exist_ok=True)\n",
        "os.makedirs(DAG_FLOW_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a4045c8a",
      "metadata": {
        "id": "a4045c8a"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "openai.api_key = userdata.get(\"OPENAI\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "413db03a",
      "metadata": {
        "id": "413db03a"
      },
      "outputs": [],
      "source": [
        "def enhance_markdown(md_text):\n",
        "    prompt = f\"\"\"You are an AI assistant markdown enhancer. Given the raw markdown below, clean and complete it by:\n",
        "- Filling in missing fields (e.g., description, input/output, category)\n",
        "- Ensuring clarity and correct formatting\n",
        "- Suggesting a better title if needed\n",
        "\n",
        "Return only the improved markdown.\n",
        "\n",
        "### Raw Markdown:\n",
        "{md_text}\n",
        "\"\"\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "02bb33f0",
      "metadata": {
        "id": "02bb33f0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def parse_markdown(md_text):\n",
        "    fields = {\n",
        "        \"title\": re.search(r\"^# (.+)\", md_text, re.MULTILINE),\n",
        "        \"description\": re.search(r\"## Description\\n([\\s\\S]+?)\\n(?:##|Category:|- Input:|- Output:|$)\", md_text),\n",
        "        \"category\": re.search(r\"Category: (.+)\", md_text),\n",
        "        \"inputs\": re.findall(r\"- Input: (.+)\", md_text),\n",
        "        \"outputs\": re.findall(r\"- Output: (.+)\", md_text),\n",
        "    }\n",
        "    return {k: (v.group(1).strip() if v else None) if not isinstance(v, list) else v for k, v in fields.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9674a8dd",
      "metadata": {
        "id": "9674a8dd"
      },
      "outputs": [],
      "source": [
        "def generate_streamlit_files(data, enhanced_md, output_folder):\n",
        "    import os\n",
        "    import json\n",
        "\n",
        "    name = data.get('title', 'untitled').lower().replace(\" \", \"_\")\n",
        "    folder = os.path.join(output_folder, name)\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    # Save enhanced markdown\n",
        "    with open(os.path.join(folder, f\"{name}.md\"), \"w\") as f:\n",
        "        f.write(enhanced_md)\n",
        "\n",
        "    # Save .py with run_ui\n",
        "    with open(os.path.join(folder, f\"{name}.py\"), \"w\") as f:\n",
        "        f.write(f\"\"\"import streamlit as st\n",
        "\n",
        "def run_ui():\n",
        "    st.title(\"{data.get('title', 'Untitled')}\")\n",
        "    st.write(\"{data.get('description', 'No description provided.')}\")\n",
        "    # Add UI logic here\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_ui()\n",
        "\"\"\")\n",
        "\n",
        "    # Save manifest.json\n",
        "    manifest = {\n",
        "        \"title\": data.get('title', 'Untitled'),\n",
        "        \"category\": data.get(\"category\", \"Uncategorized\"),\n",
        "        \"uses_gpt\": \"gpt\" in enhanced_md.lower(),\n",
        "        \"has_run_ui\": True,\n",
        "        \"path\": folder\n",
        "    }\n",
        "    with open(os.path.join(folder, \"manifest.json\"), \"w\") as f:\n",
        "        json.dump(manifest, f, indent=2)\n",
        "\n",
        "    # Save README.md\n",
        "    with open(os.path.join(folder, \"README.md\"), \"w\") as f:\n",
        "        f.write(f\"# {data.get('title', 'Untitled')}\\n\\n\")\n",
        "        f.write(f\"## Description\\n{data.get('description', 'N/A')}\\n\\n\")\n",
        "        f.write(f\"### Category\\n{data.get('category', 'Uncategorized')}\\n\\n\")\n",
        "        f.write(\"### Inputs\\n\")\n",
        "        for input_item in data.get(\"inputs\", []):\n",
        "            f.write(f\"- {input_item}\\n\")\n",
        "        f.write(\"\\n### Outputs\\n\")\n",
        "        for output_item in data.get(\"outputs\", []):\n",
        "            f.write(f\"- {output_item}\\n\")\n",
        "\n",
        "    return folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cafbe30f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cafbe30f",
        "outputId": "422d7e2c-64ae-4324-eae9-811f30c5858e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pipeline_designer_phase1.py written to: /content/drive/MyDrive/assistant_markdown/streamlit_ready/pipeline_designer_phase1.py\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Write DAG Phase 1\n",
        "dag_code = \"\"\"import streamlit as st\n",
        "from streamlit_dag import Dag, Task\n",
        "import json\n",
        "import os\n",
        "\n",
        "st.set_page_config(page_title=\"üß± DAG Flow Builder\", layout=\"wide\")\n",
        "st.title(\"üß± DAG Flow Builder ‚Äì Phase 1: Visual Enhancements\")\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "CATEGORY_STYLES = {\n",
        "    \"Data Cleaning\": {\"color\": \"#4BA3C7\", \"icon\": \"üßπ\"},\n",
        "    \"Data Structuring\": {\"color\": \"#FFD166\", \"icon\": \"üß±\"},\n",
        "    \"Data Enrichment\": {\"color\": \"#EF476F\", \"icon\": \"‚ú®\"},\n",
        "    \"Validation & QA\": {\"color\": \"#06D6A0\", \"icon\": \"‚úÖ\"},\n",
        "    \"Export\": {\"color\": \"#118AB2\", \"icon\": \"üì§\"},\n",
        "    \"Uncategorized\": {\"color\": \"#CCCCCC\", \"icon\": \"‚ùì\"},\n",
        "}\n",
        "\n",
        "# === MOCKED ASSISTANTS (can be loaded dynamically later) ===\n",
        "assistants = [\n",
        "    {\"id\": \"clean_nulls\", \"title\": \"Clean Nulls\", \"category\": \"Data Cleaning\"},\n",
        "    {\"id\": \"normalize_columns\", \"title\": \"Normalize Columns\", \"category\": \"Data Structuring\"},\n",
        "    {\"id\": \"detect_outliers\", \"title\": \"Detect Outliers\", \"category\": \"Validation & QA\"},\n",
        "    {\"id\": \"merge_datasets\", \"title\": \"Merge Datasets\", \"category\": \"Data Structuring\"},\n",
        "    {\"id\": \"export_to_api\", \"title\": \"Export to API\", \"category\": \"Export\"},\n",
        "]\n",
        "\n",
        "# === BUILD TASKS WITH STYLES ===\n",
        "def style_node(node):\n",
        "    cat = node.get(\"category\", \"Uncategorized\")\n",
        "    style = CATEGORY_STYLES.get(cat, CATEGORY_STYLES[\"Uncategorized\"])\n",
        "    return Task(\n",
        "        id=node[\"id\"],\n",
        "        label=f\"{style['icon']} {node['title']}\",\n",
        "        style={\"backgroundColor\": style[\"color\"], \"borderRadius\": \"10px\", \"boxShadow\": \"2px 2px 5px rgba(0,0,0,0.2)\"},\n",
        "    )\n",
        "\n",
        "nodes = [style_node(a) for a in assistants]\n",
        "edges = [(\"clean_nulls\", \"normalize_columns\"), (\"normalize_columns\", \"detect_outliers\")]\n",
        "\n",
        "# === LAYOUT ===\n",
        "st.subheader(\"üé® Styled Assistant Graph\")\n",
        "with Dag(nodes, edges, direction=\"LR\", node_spacing=60, layer_spacing=80) as result:\n",
        "    st.write(\"üì¶ Current flow:\", result)\n",
        "\n",
        "# === HOVER TOOLTIP MOCKUP ===\n",
        "st.markdown(\"‚ÑπÔ∏è Hover over each node to view assistant category and color.\")\n",
        "\"\"\"\n",
        "dag_path = os.path.join(LAUNCHER_DIR, \"pipeline_designer_phase1.py\")\n",
        "with open(dag_path, \"w\") as f:\n",
        "    f.write(dag_code)\n",
        "print(f\"‚úÖ pipeline_designer_phase1.py written to:\", dag_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bf645839",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf645839",
        "outputId": "5f0953b0-2934-44fc-85d0-fc4ad9363690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pipeline_designer_phase2.py written to: /content/drive/MyDrive/assistant_markdown/streamlit_ready/pipeline_designer_phase2.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ‚úÖ Write DAG Phase 2\n",
        "dag_code = \"\"\"import streamlit as st\n",
        "from streamlit_dag import Dag, Task\n",
        "import openai\n",
        "import os\n",
        "\n",
        "st.set_page_config(page_title=\"üß† GPT DAG Builder\", layout=\"wide\")\n",
        "st.title(\"üß† DAG Flow Builder ‚Äì Phase 2: GPT Enhancements\")\n",
        "\n",
        "# --- SETUP ---\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"sk-REPLACE_ME\")  # Use your actual key or load from env\n",
        "\n",
        "CATEGORY_STYLES = {\n",
        "    \"Data Cleaning\": {\"color\": \"#4BA3C7\", \"icon\": \"üßπ\"},\n",
        "    \"Data Structuring\": {\"color\": \"#FFD166\", \"icon\": \"üß±\"},\n",
        "    \"Data Enrichment\": {\"color\": \"#EF476F\", \"icon\": \"‚ú®\"},\n",
        "    \"Validation & QA\": {\"color\": \"#06D6A0\", \"icon\": \"‚úÖ\"},\n",
        "    \"Export\": {\"color\": \"#118AB2\", \"icon\": \"üì§\"},\n",
        "    \"Uncategorized\": {\"color\": \"#CCCCCC\", \"icon\": \"‚ùì\"},\n",
        "}\n",
        "\n",
        "# --- SIDEBAR: GPT GOAL FLOW ---\n",
        "st.sidebar.title(\"ü™Ñ GPT Auto-Builder\")\n",
        "goal = st.sidebar.text_input(\"Describe your pipeline goal:\")\n",
        "if st.sidebar.button(\"‚ö° Generate DAG from Goal\"):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Given the goal '{goal}', suggest a 3-5 step assistant pipeline with titles and categories.\"\n",
        "            }],\n",
        "            temperature=0.4\n",
        "        )\n",
        "        st.session_state['gpt_dag_result'] = response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        st.sidebar.error(f\"GPT error: {e}\")\n",
        "\n",
        "if 'gpt_dag_result' in st.session_state:\n",
        "    st.sidebar.markdown(\"### üß† Suggested Flow:\")\n",
        "    st.sidebar.code(st.session_state['gpt_dag_result'])\n",
        "\n",
        "# --- MOCKED DATA (later replaced by dynamic flow)\n",
        "assistants = [\n",
        "    {\"id\": \"clean_nulls\", \"title\": \"Clean Nulls\", \"category\": \"Data Cleaning\"},\n",
        "    {\"id\": \"normalize_columns\", \"title\": \"Normalize Columns\", \"category\": \"Data Structuring\"},\n",
        "    {\"id\": \"detect_outliers\", \"title\": \"Detect Outliers\", \"category\": \"Validation & QA\"},\n",
        "    {\"id\": \"merge_datasets\", \"title\": \"Merge Datasets\", \"category\": \"Data Structuring\"},\n",
        "    {\"id\": \"export_to_api\", \"title\": \"Export to API\", \"category\": \"Export\"},\n",
        "]\n",
        "\n",
        "def style_node(node):\n",
        "    cat = node.get(\"category\", \"Uncategorized\")\n",
        "    style = CATEGORY_STYLES.get(cat, CATEGORY_STYLES[\"Uncategorized\"])\n",
        "    return Task(\n",
        "        id=node[\"id\"],\n",
        "        label=f\"{style['icon']} {node['title']}\",\n",
        "        style={\"backgroundColor\": style[\"color\"], \"borderRadius\": \"10px\", \"boxShadow\": \"2px 2px 5px rgba(0,0,0,0.2)\"}\n",
        "    )\n",
        "\n",
        "nodes = [style_node(a) for a in assistants]\n",
        "edges = [(\"clean_nulls\", \"normalize_columns\"), (\"normalize_columns\", \"detect_outliers\")]\n",
        "\n",
        "# --- MAIN DAG DISPLAY ---\n",
        "st.subheader(\"üé® Styled DAG with GPT Support\")\n",
        "with Dag(nodes, edges, direction=\"LR\", node_spacing=60, layer_spacing=80) as result:\n",
        "    st.write(\"üì¶ Current flow:\", result)\n",
        "\n",
        "# --- GPT Assistant Suggestion (per node) ---\n",
        "st.markdown(\"### üîÆ Suggest Next Assistant\")\n",
        "selected_node = st.selectbox(\"Select current node\", [a['title'] for a in assistants])\n",
        "if st.button(\"üí° GPT: What comes next?\"):\n",
        "    try:\n",
        "        prompt = f\"I'm building a data pipeline. After the step '{selected_node}', what assistant should come next?\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.5\n",
        "        )\n",
        "        st.success(response.choices[0].message.content.strip())\n",
        "    except Exception as e:\n",
        "        st.error(f\"GPT error: {e}\")\n",
        "\n",
        "# --- PIPELINE SUMMARY ---\n",
        "if st.button(\"üß† Summarize Pipeline\"):\n",
        "    try:\n",
        "        steps = \", then \".join([a[\"title\"] for a in assistants])\n",
        "        prompt = f\"Summarize the purpose of this pipeline: {steps}.\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3\n",
        "        )\n",
        "        st.info(response.choices[0].message.content.strip())\n",
        "    except Exception as e:\n",
        "        st.error(f\"GPT error: {e}\")\n",
        "\"\"\"\n",
        "dag_path = os.path.join(LAUNCHER_DIR, \"pipeline_designer_phase2.py\")\n",
        "with open(dag_path, \"w\") as f:\n",
        "    f.write(dag_code)\n",
        "print(f\"‚úÖ pipeline_designer_phase2.py written to:\", dag_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4d94c67d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d94c67d",
        "outputId": "41c42a16-09bf-4214-9493-46ff3aeab85c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pipeline_designer_phase3.py written to: /content/drive/MyDrive/assistant_markdown/streamlit_ready/pipeline_designer_phase3.py\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Write DAG Phase 3\n",
        "dag_code = \"\"\"import streamlit as st\n",
        "from streamlit_dag import Dag, Task\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "st.set_page_config(page_title=\"üíæ DAG Builder ‚Äì Phase 3\", layout=\"wide\")\n",
        "st.title(\"üíæ DAG Builder ‚Äì Phase 3: Save, Load, Export\")\n",
        "\n",
        "# --- Path setup ---\n",
        "FLOW_DIR = \"/content/drive/MyDrive/assistant_markdown/dag_flows/\"\n",
        "os.makedirs(FLOW_DIR, exist_ok=True)\n",
        "\n",
        "# --- Assistant templates ---\n",
        "CATEGORY_STYLES = {\n",
        "    \"Data Cleaning\": {\"color\": \"#4BA3C7\", \"icon\": \"üßπ\"},\n",
        "    \"Data Structuring\": {\"color\": \"#FFD166\", \"icon\": \"üß±\"},\n",
        "    \"Data Enrichment\": {\"color\": \"#EF476F\", \"icon\": \"‚ú®\"},\n",
        "    \"Validation & QA\": {\"color\": \"#06D6A0\", \"icon\": \"‚úÖ\"},\n",
        "    \"Export\": {\"color\": \"#118AB2\", \"icon\": \"üì§\"},\n",
        "    \"Uncategorized\": {\"color\": \"#CCCCCC\", \"icon\": \"‚ùì\"},\n",
        "}\n",
        "\n",
        "# Default mock flow\n",
        "default_assistants = [\n",
        "    {\"id\": \"clean_nulls\", \"title\": \"Clean Nulls\", \"category\": \"Data Cleaning\"},\n",
        "    {\"id\": \"normalize_columns\", \"title\": \"Normalize Columns\", \"category\": \"Data Structuring\"},\n",
        "    {\"id\": \"detect_outliers\", \"title\": \"Detect Outliers\", \"category\": \"Validation & QA\"},\n",
        "    {\"id\": \"merge_datasets\", \"title\": \"Merge Datasets\", \"category\": \"Data Structuring\"},\n",
        "    {\"id\": \"export_to_api\", \"title\": \"Export to API\", \"category\": \"Export\"},\n",
        "]\n",
        "default_edges = [(\"clean_nulls\", \"normalize_columns\"), (\"normalize_columns\", \"detect_outliers\")]\n",
        "\n",
        "# Session state\n",
        "if \"nodes\" not in st.session_state:\n",
        "    st.session_state.nodes = default_assistants\n",
        "if \"edges\" not in st.session_state:\n",
        "    st.session_state.edges = default_edges\n",
        "\n",
        "# Build styled DAG nodes\n",
        "def style_node(node):\n",
        "    cat = node.get(\"category\", \"Uncategorized\")\n",
        "    style = CATEGORY_STYLES.get(cat, CATEGORY_STYLES[\"Uncategorized\"])\n",
        "    return Task(\n",
        "        id=node[\"id\"],\n",
        "        label=f\"{style['icon']} {node['title']}\",\n",
        "        style={\"backgroundColor\": style[\"color\"], \"borderRadius\": \"10px\", \"boxShadow\": \"2px 2px 5px rgba(0,0,0,0.2)\"}\n",
        "    )\n",
        "\n",
        "styled_nodes = [style_node(n) for n in st.session_state.nodes]\n",
        "\n",
        "# UI: DAG Display\n",
        "st.subheader(\"üß± DAG Canvas\")\n",
        "with Dag(styled_nodes, st.session_state.edges, direction=\"LR\", node_spacing=60, layer_spacing=80) as result:\n",
        "    st.write(\"üîó Flow result:\", result)\n",
        "\n",
        "# üíæ SAVE FLOW\n",
        "if st.button(\"üíæ Save Flow as JSON\"):\n",
        "    flow_data = {\n",
        "        \"nodes\": st.session_state.nodes,\n",
        "        \"edges\": st.session_state.edges\n",
        "    }\n",
        "    filename = f\"dag_flow_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(os.path.join(FLOW_DIR, filename), \"w\") as f:\n",
        "        json.dump(flow_data, f, indent=2)\n",
        "    st.success(f\"Saved to {filename}\")\n",
        "\n",
        "# üìÇ LOAD FLOW\n",
        "flow_files = [f for f in os.listdir(FLOW_DIR) if f.endswith(\".json\")]\n",
        "selected_flow = st.selectbox(\"üìÇ Load existing flow\", [\"-- Select --\"] + flow_files)\n",
        "\n",
        "if selected_flow != \"-- Select --\":\n",
        "    with open(os.path.join(FLOW_DIR, selected_flow)) as f:\n",
        "        loaded = json.load(f)\n",
        "        st.session_state.nodes = loaded[\"nodes\"]\n",
        "        st.session_state.edges = loaded[\"edges\"]\n",
        "    st.success(f\"Loaded flow: {selected_flow}\")\n",
        "\n",
        "# üìù EXPORT AS MARKDOWN\n",
        "if st.button(\"üìÑ Export Flow as Markdown\"):\n",
        "    lines = [\"# DAG Flow Summary\\n\"]\n",
        "    for n in st.session_state.nodes:\n",
        "        lines.append(f\"## {n['title']}\")\n",
        "        lines.append(f\"- ID: `{n['id']}`\")\n",
        "        lines.append(f\"- Category: `{n.get('category', 'N/A')}`\\n\")\n",
        "    st.download_button(\"üì• Download Markdown\", data=\"\\n\".join(lines), file_name=\"dag_flow_summary.md\")\n",
        "\"\"\"\n",
        "dag_path = os.path.join(LAUNCHER_DIR, \"pipeline_designer_phase3.py\")\n",
        "with open(dag_path, \"w\") as f:\n",
        "    f.write(dag_code)\n",
        "print(f\"‚úÖ pipeline_designer_phase3.py written to:\", dag_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "071dfe9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "071dfe9a",
        "outputId": "97ead4f0-001f-4433-9d1b-a53b79ea8980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pipeline_designer_phase4.py written to: /content/drive/MyDrive/assistant_markdown/streamlit_ready/pipeline_designer_phase4.py\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Write DAG Phase 4\n",
        "dag_code = \"\"\"import streamlit as st\n",
        "from streamlit_dag import Dag, Task\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "from copy import deepcopy\n",
        "\n",
        "st.set_page_config(page_title=\"üõ†Ô∏è DAG Builder ‚Äì Phase 4\", layout=\"wide\")\n",
        "st.title(\"üõ†Ô∏è DAG Builder ‚Äì Phase 4: Full UX + GPT Simulation\")\n",
        "\n",
        "# GPT Setup\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"sk-REPLACE_ME\")\n",
        "\n",
        "# State\n",
        "if \"nodes\" not in st.session_state:\n",
        "    st.session_state.nodes = []\n",
        "if \"edges\" not in st.session_state:\n",
        "    st.session_state.edges = []\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "CATEGORY_STYLES = {\n",
        "    \"Data Cleaning\": {\"color\": \"#4BA3C7\", \"icon\": \"üßπ\"},\n",
        "    \"Data Structuring\": {\"color\": \"#FFD166\", \"icon\": \"üß±\"},\n",
        "    \"Data Enrichment\": {\"color\": \"#EF476F\", \"icon\": \"‚ú®\"},\n",
        "    \"Validation & QA\": {\"color\": \"#06D6A0\", \"icon\": \"‚úÖ\"},\n",
        "    \"Export\": {\"color\": \"#118AB2\", \"icon\": \"üì§\"},\n",
        "    \"Uncategorized\": {\"color\": \"#CCCCCC\", \"icon\": \"‚ùì\"},\n",
        "}\n",
        "\n",
        "# Node Library (static for now)\n",
        "node_library = [\n",
        "    {\"title\": \"Clean Nulls\", \"category\": \"Data Cleaning\"},\n",
        "    {\"title\": \"Normalize Columns\", \"category\": \"Data Structuring\"},\n",
        "    {\"title\": \"Detect Outliers\", \"category\": \"Validation & QA\"},\n",
        "    {\"title\": \"Merge Datasets\", \"category\": \"Data Structuring\"},\n",
        "    {\"title\": \"Export to API\", \"category\": \"Export\"},\n",
        "]\n",
        "\n",
        "def generate_node_id(title):\n",
        "    return title.lower().replace(\" \", \"_\") + \"_\" + str(len(st.session_state.nodes))\n",
        "\n",
        "# Sidebar: Node Library\n",
        "st.sidebar.title(\"üìö Node Library\")\n",
        "search = st.sidebar.text_input(\"Search Assistants\")\n",
        "filtered = [n for n in node_library if search.lower() in n[\"title\"].lower()]\n",
        "\n",
        "for item in filtered:\n",
        "    if st.sidebar.button(f\"‚ûï Add: {item['title']}\"):\n",
        "        new_id = generate_node_id(item[\"title\"])\n",
        "        st.session_state.history.append((deepcopy(st.session_state.nodes), deepcopy(st.session_state.edges)))\n",
        "        st.session_state.nodes.append({\n",
        "            \"id\": new_id,\n",
        "            \"title\": item[\"title\"],\n",
        "            \"category\": item[\"category\"]\n",
        "        })\n",
        "\n",
        "# Sidebar: Undo/Redo\n",
        "st.sidebar.markdown(\"---\")\n",
        "if st.sidebar.button(\"‚Ü©Ô∏è Undo\"):\n",
        "    if st.session_state.history:\n",
        "        last_nodes, last_edges = st.session_state.history.pop()\n",
        "        st.session_state.nodes = last_nodes\n",
        "        st.session_state.edges = last_edges\n",
        "\n",
        "# Build Task objects\n",
        "def style_node(node):\n",
        "    cat = node.get(\"category\", \"Uncategorized\")\n",
        "    style = CATEGORY_STYLES.get(cat, CATEGORY_STYLES[\"Uncategorized\"])\n",
        "    return Task(\n",
        "        id=node[\"id\"],\n",
        "        label=f\"{style['icon']} {node['title']}\",\n",
        "        style={\"backgroundColor\": style[\"color\"], \"borderRadius\": \"10px\", \"boxShadow\": \"2px 2px 5px rgba(0,0,0,0.2)\"}\n",
        "    )\n",
        "\n",
        "tasks = [style_node(n) for n in st.session_state.nodes]\n",
        "\n",
        "st.subheader(\"üéØ DAG Canvas\")\n",
        "with Dag(tasks, st.session_state.edges, direction=\"LR\", node_spacing=60, layer_spacing=80) as result:\n",
        "    st.write(\"üß© Flow result:\", result)\n",
        "    # Allow edge creation through canvas\n",
        "    if result[\"added_edges\"]:\n",
        "        st.session_state.edges += result[\"added_edges\"]\n",
        "\n",
        "# GPT Simulation\n",
        "if st.button(\"üß™ Run Simulation\"):\n",
        "    if not st.session_state.nodes:\n",
        "        st.warning(\"No nodes to simulate.\")\n",
        "    else:\n",
        "        try:\n",
        "            steps = \", then \".join([n[\"title\"] for n in st.session_state.nodes])\n",
        "            prompt = f\"Simulate what this assistant pipeline will do: {steps}.\"\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.4\n",
        "            )\n",
        "            st.info(response.choices[0].message.content.strip())\n",
        "        except Exception as e:\n",
        "            st.error(f\"GPT error: {e}\")\n",
        "\"\"\"\n",
        "dag_path = os.path.join(LAUNCHER_DIR, \"pipeline_designer_phase4.py\")\n",
        "with open(dag_path, \"w\") as f:\n",
        "    f.write(dag_code)\n",
        "print(f\"‚úÖ pipeline_designer_phase4.py written to:\", dag_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EAGjBr5glT2i"
      },
      "id": "EAGjBr5glT2i",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}